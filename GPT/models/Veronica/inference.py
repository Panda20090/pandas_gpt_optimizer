import os
import json
import time
from transformers import GPT2Tokenizer, GPT2LMHeadModel

# Define output directory for consistency
output_dir = os.path.join(os.path.dirname(__file__), '../models/Veronica/training_data')
os.makedirs(output_dir, exist_ok=True)

# Load the tokenizer and model
model_dir = "models/Veronica"
tokenizer = GPT2Tokenizer.from_pretrained(model_dir)
model = GPT2LMHeadModel.from_pretrained(model_dir)

def generate_text(prompt, max_length=150):
    """
    Generate text using the Veronica model.

    Parameters:
        prompt (str): Prompt text to generate from.
        max_length (int): Maximum length of the generated text.

    Returns:
        str: Generated text from the model.
    """
    inputs = tokenizer(prompt, return_tensors='pt')
    outputs = model.generate(
        inputs['input_ids'],
        max_length=max_length,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        num_beams=5,
        temperature=0.7,
        top_k=50,
        top_p=0.95
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def summarize_code_veronica(file_content):
    """
    Summarize the provided code content using the Veronica model.

    Parameters:
        file_content (str): The content of the code file.

    Returns:
        str: Summary of the code.
    """
    prompt = f"Summarize the following code:\n\n{file_content}"
    summary = generate_text(prompt)
    log_training_data('summarize', file_content, summary)
    return summary

def verify_code_veronica(file_content):
    """
    Verify the provided code content using the Veronica model.

    Parameters:
        file_content (str): The content of the code file.

    Returns:
        str: Verification result of the code.
    """
    prompt = f"Verify the following code and its dependencies:\n\n{file_content}"
    verification = generate_text(prompt)
    log_training_data('verify', file_content, verification)
    return verification

def get_corrections_veronica(file_content):
    """
    Get corrections for the provided code content using the Veronica model.

    Parameters:
        file_content (str): The content of the code file.

    Returns:
        str: Corrections for the code.
    """
    prompt = f"Provide corrections for the following code:\n\n{file_content}"
    corrections = generate_text(prompt)
    log_training_data('corrections', file_content, corrections)
    return corrections

def log_training_data(operation, input_data, output_data):
    """
    Log training data for the Veronica model.

    Parameters:
        operation (str): The operation performed (summarize, verify, corrections).
        input_data (str): The input data provided to the model.
        output_data (str): The output data generated by the model.
    """
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    log_entry = {
        'operation': operation,
        'input': input_data,
        'output': output_data
    }
    log_file = os.path.join(output_dir, f"{operation}_{timestamp}.json")
    with open(log_file, 'w') as f:
        json.dump(log_entry, f, indent=4)

def log_error(input_data, error_message):
    """
    Log errors encountered during model operations.

    Parameters:
        input_data (str): The input data provided to the model.
        error_message (str): The error message encountered.
    """
    error_log_path = os.path.join(output_dir, "error.txt")
    error_entry = {
        'input': input_data,
        'error': error_message
    }
    with open(error_log_path, 'a') as f:
        json.dump(error_entry, f, indent=4)
        f.write("\n")

if __name__ == "__main__":
    test_content = "def example_function(x, y): return x + y"
    summary = summarize_code_veronica(test_content)
    print(f"Summary: {summary}")
    verification = verify_code_veronica(test_content)
    print(f"Verification: {verification}")
    corrections = get_corrections_veronica(test_content)
    print(f"Corrections: {corrections}")
